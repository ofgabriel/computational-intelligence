\documentclass{homework}

\usepackage{tikz}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{systeme}
\usepackage{enumitem}
\usepackage{xcolor}

\lstset
{ %Formatting for code in appendix
    basicstyle=\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}
\setlength{\parindent}{4em}

\title{Inteligência Computacional --- COC 361\linebreak2021/2 \linebreak\linebreak Trabalho Computacional}
\author{Gabriel de Oliveira da Fonseca, Gustavo Pires Machado}

\begin{document}

\maketitle

\section{Introdução}

\begin{itemize}
\color{red}
    \item Descrição do problema.
    \item Pesquisa bibliográfica (opcional).
\end{itemize}

Para o presente trabalho, o conjunto de dados escolhido reúne dados coletados entre 1º de Julho de 2015 e 31 de Agosto
de 2017 por uma rede hoteleira que incluem diversos atributos relacionados às reservas efetuadas por seus clientes.
Utilizando-se das diversas metodologias de Inteligência Computacional discutidas ao longo do curso, o trabalho tem por
objetivo a construção de um modelo de classifcação para a previsão de reservas canceladas. A partir deste modelo,
espera-se que a rede hoteleira possa se beneficiar de uma maior previsibilidade das reservas que serão efetivamente
concretizadas, aumentando por fim sua margem de lucro.

\section{Dataset e Tecnologia}

\begin{itemize}
\color{red}
    \item Descrição dos Dados.
    \item Apresentação da tecnologia.
\end{itemize}

O dataset escolhido possui 36 colunas, foi retirado da plataforma Kaggle \cite{kaggle}, e conta com $119390$ entradas. 
De forma geral, está razoavelmente organizado e possui um baixo número de dados faltantes (nulos). Os dados presentes
compreendem diversos aspectos relacionados às reservas, como número de hóspedes em diferentes faixas etárias, dados
pessoais dos clientes (como nome, e-mail e telefone), além de nuances mais promissoras, como indicadores de que um
determinado cliente já cancelou reservas anteriormente.

Um outro importante aspecto a ser analisado diz respeito à qual classe pertence o conjunto de dados: balanceada ou
desbalanceada. Isso pode ser visto através da predominância das classes alvo, que nesse estudo são as reservas
canceladas ou não. Contando cada uma das classes, chegamos à proporção de 39\% das reservas canceladas para 61\% não
canceladas. Dessa forma, conclui-se que o dataset é razoavelmente balanceado.

Além disso, conforme disposto na tabela abaixo, 20 de suas colunas são numéricas, e portanto 16 categóricas.

\begin{table}[h!]
\centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{\#} & \textbf{Coluna} & \textbf{\# entradas não-nulas} & \textbf{Tipo} \\
        \hline
        0 & hotel & 119390 & object \\
        \hline
        1 & is\_canceled & 119390 & int64 \\
        \hline
        2 & lead\_time & 119390 & int64 \\
        \hline
        3 & arrival\_date\_year & 119390 & int64 \\
        \hline
        4 & arrival\_date\_month & 119390 & object \\
        \hline
        5 & arrival\_date\_week\_number & 119390 & int64 \\
        \hline
        6 & arrival\_date\_day\_of\_month & 119390 & int64 \\
        \hline
        7 & stays\_in\_weekend\_nights & 119390 & int64 \\
        \hline
        8 & stays\_in\_week\_nights & 119390 & int64 \\
        \hline
        9 & adults & 119390 & int64 \\
        \hline
        10 & children & 119386 & float64 \\
        \hline
        11 & babies & 119390 & int64 \\
        \hline
        12 & meal & 119390 & object \\
        \hline
        13 & country & 118902 & object \\
        \hline
        14 & market\_segment & 119390 & object \\
        \hline
        15 & distribution\_channel & 119390 & object \\
        \hline
        16 & is\_repeated\_guest & 119390 & int64 \\
        \hline
        17 & previous\_cancellations & 119390 & int64 \\
        \hline
        18 & previous\_bookings\_not\_canceled & 119390 & int64 \\
        \hline
        19 & reserved\_room\_type & 119390 & object \\
        \hline
        20 & assigned\_room\_type & 119390 & object \\
        \hline
        21 & booking\_changes & 119390 & int64 \\
        \hline
        22 & deposit\_type & 119390 & object \\
        \hline
        23 & agent & 103050 & float64 \\
        \hline
        24 & company & 6797 & float64 \\
        \hline
        25 & days\_in\_waiting\_list & 119390 & int64 \\
        \hline
        26 & customer\_type & 119390 & object \\
        \hline
        27 & adr & 119390 & float64 \\
        \hline
        28 & required\_car\_parking\_spaces & 119390 & int64 \\
        \hline
        29 & total\_of\_special\_requests & 119390 & int64 \\
        \hline
        30 & reservation\_status & 119390 & object \\
        \hline
        31 & reservation\_status\_date & 119390 & object \\
        \hline
        32 & name & 119390 & object \\
        \hline
        33 & email & 119390 & object \\
        \hline
        34 & phone-number & 119390 & object \\
        \hline
        35 & credit\_card & 119390 & object \\
        \hline
    \end{tabular}
    \caption{Atributos do dataset.}
    \label{attributes}
\end{table}

Já em relação às tecnologias utilizadas para a implementação da solução deste trabalho, foram adotadas essencialmente a
plataforma Google Collaboratory \cite{colab}, onde o trabalho foi desenvolvido no formato de um notebook Jupyter, e
diversas bibiliotecas em Python. Dentre as bibliotecas utilizadas, vale citar a Pandas, que implementa abstrações para
facilitar o manuseio de data frames, bem como Scikit-Learn, que disponibiliza uma vasta gama de ferramentas para
visualização de dados e treinamento de modelos. Especificamente, também foi utilizada a API Keras do TensorFlow, que foi
utilizada no treinamento dos modelos de redes neurais.

\section{Metodologia}

\begin{itemize}
    \color{red}
        \item Apresentação da solução do problema proposto.
        \item Descrição teórica (matemática) dos modelos utilizados.
\end{itemize}

A solução construída para o problema consistiu na implementação de um ferramental de modelos de classificação baseados
em diversos algoritmos apresentados ao longo da disciplina de Inteligência Computacional. Como tarefa preliminar,
conforme apresentado posteriormente na seção \ref{resultados}, foi realizada também uma série de ajustes de
pré-processamento no dataset a fim de otimizar os modelos treinados. Nas subseções a seguir, são apresentados
detalhadamente os modelos adotados para construção da solução.

\subsection{Regressão Logística}

A Regressão Logística é um modelo de classificação binária, cuja função discriminante é definida pela probablidade
\textit{a posteriori} como \cite{evsukoff}:
\begin{equation}
    \begin{split}
        P(v(t)) = 1|\mathbf{x}(t),\mathbf{\theta}) = g(\mathbf{x}(t),\mathbf{\theta}) \\
        P(v(t)) = 0|\mathbf{x}(t),\mathbf{\theta}) = 1 - g(\mathbf{x}(t),\mathbf{\theta})
    \end{split}
\end{equation}

Tal função de probabilidade em representar os valores observados é maximizada pelo modelo através da seguinte função
objetivo:
\begin{equation}
    l(\mathbf{\theta}) = - \sum_{t=1}^{N}v(t)log(\hat{v}(t)) + (1-v(t))log(1-\hat{v}(t))
\end{equation}

Onde,
\begin{equation}
    \hat{v}(t) = \frac{1}{1+e^{-\theta T x}}
\end{equation}

Pela equação (3.2), observa-se que quando $v(t) = 0$, apenas o segundo termo do somatório prevalece e o custo
tende a infinito ($log(0)$) no caso em que $\hat{v}(t) = 1$. Situação similar ocorre quando $v(t) = 1$ e $\hat{v}(t)=0$.
Sabendo que esta função objetivo determina o erro entre a classe predita e a classe observada, pode-se minimizá-la
utilizando métodos de PNL como o do gradiente. Dessa forma, construímos uma superfície de separação entre as classes,
discriminada por uma curva sigmóide, como dado pela equação (3.3).

\subsection{Classificação Bayesiana}

O teorema de Bayes relaciona o conhecimento prévio do problema na forma da seguinte equação:
\begin{equation}
    P(C_i|\mathbf{x}) = \frac{p(\mathbf{x}|C_i)P(C_i)}{p(\mathbf{x})}
\end{equation}

Onde $P(C_i|\mathbf{x})$ é a probabilidade de observar a classe $C_i$ dado que os valores das variáveis $\mathbf{x}$ são
conhecidos, chamada \textbf{probabilidade \textit{a posteriori}}; $p(\mathbf{x}|C_i)$ representa a distribuição de
probabilidades das variáveis $\mathbf{x}$ quando a classe observada é $C_i$, chamada de distribuição de 
\textbf{probabilidade condicional}; e $P(C_i)$ é a probabilidade de ocorrência da classe $C_i$ na ausência de qualquer
observação, chamada \textbf{probabilidade \textit{a priori}}. Por fim, o denominador é apenas a probabilidade de
observar valores das variáveis $\mathbf{x}$, e funciona como um fator de padronização \cite{evsukoff}.

O modelo de Classificação Bayesiana faz uso do teorema de Bayes para decidir qual classe tem a maior probabilidade
condicional, e portanto será escolhida. Para isso, as probabilidades condicionais são calculadas diretamenta pela
definição quando se tratando de atributos nominais, e através da PDF do atributo aplicada em $x$ para variáveis
numéricas. Por fim, a probabilidade condicional geral para cada classe será dada pelo produtório das probabilidades
condicionais de cada atributo.

\subsection{Árvores de Decisão}
\label{dt}

Árvores de Decisão são modelos de aprendizado supervisionado que podem ser utilizados tanto para classificação quanto
para regressão. De forma ampla, buscam definir um modelo de predição através do aprendizado de regras inferidas pelos
atributos do dataset. São chamadas de árvore pois o modelo é construído como um diagrama de decisão, cuja representação
é similar a uma árvore, conforme ilustrado abaixo:

\begin{figure}[h!]
    \centerline{\includegraphics[scale=2]{decision_tree.png}}
    \label{decision_tree}
    \caption{Exemplo de Árvore de Decisão \cite{decision_tree}}
\end{figure}

A predição de uma classe é baseada essencialmente em percorrer o diagrama utilizando os valores dos atributos conhecidos
como entrada para as regras inferidas pelo modelo. A acurácia do modelo está, portanto, diretamente correlacionada à
inferência das regras e também ao tamanho que a árvore pode adotar, o que permite uma maior especificidade das regras
inferidas.

\subsection{Random Forest}

Modelos do tipo Random Forest realizam a agregação de diversas Árvores de Decisão (DT, do inglês \textit{decision tree}),
já explicadas na subseção \ref{decision_tree}, para composição de classificadores ou regressores. Para o problema
específico de classificação, a saída de uma Random Forest é a classe selecionada pela maioria das DTs. Já para
regressões, são retornadas as médias dos valores retornados por cada DT \cite{random_forest}.

O objetivo central na construção do modelo é diminuir a variância entre as saídas das DTs e ao mesmo tempo evitar
\textit{overfitting} - que ocorre quando o modelo é específico demais para o conjunto de treinamento e apresenta baixa
acurácia para conjuntos de teste. Para isso, o número de DTs utilizadas é configurável através de um hiperparâmetro, o
que permite realizar um ajuste que propicie a menor variância possível para análise.

\subsection{Gradient Boosting}

O método de Gradient Boosting preconiza a construção de um modelo preditivo forte a partir de modelos intermediários
fracos - ideia geral dos algoritmos de Boosting-, normalmente DTs. É similar, portanto, ao de Random Forest no que tange
a utilização de DTs como elementos de construção do modelo preditivo final. Diferem, entretanto, na forma como os
diferentes modelos intermediários (DTs) são agregados, já que no Gradient Boosting eles são sequencialmente adicionados,
enquanto em Random Forest são utilizados em paralelo.

O algoritmo de Gradient Boosting consiste em realizar o treinamento de um modelo fraco inicial e aplicar à ele próprio
uma função de correção a fim de melhorar a acurácia de um novo modelo a ser criado para o mesmo conjunto de dados. Nesse
caso, como o nome do método sugere, a função de correção é derivada do gradiente da função em cada etapa da interação,
conforme a seguinte equação:
\begin{equation}
    F_{m+1}(x) = F_m(x) + h_m(x)
\end{equation}

Onde $h_m(x)$ é a função de correção, que será o gradiente da função de avaliação utilizada para o problema. Além disso,
o método possui 3 hiperparâmetros: tamanho da árvore, taxa de aprendizado e subamostra. Os dois últimos servem,
respectivamente, para controlar a proporção em que a função de correção é adicionada e o particionamento da amostra
original durante a construção do modelo.

\subsection{SVM}

O método de Support Vector Machine (SVM) consiste na utilização das chamadas funções de núcleo para manipular o espaço
de características de um dado problema de forma indireta a fim de obter uma medida de similaridade entre diferentes
entradas do conjunto de dados. A partir da aplicação da função de núcleo, é construída então uma matriz de núcleo, que
contém uma representação do conjunto inicial com suas respectivas similaridades em relação a todos os outros registros.
Esse matriz é, posteriormente, utilizada para construção de um hiperplano que separa as diferentes classes alvo.

A fim de minimizar o erro de classificação produzido pelo método, o conceito de margem de separação é adotado no SVM, e
consiste em definir um limiar definido a partir do hiperplano para o qual o modelo é capaz de realizar classificações
corretas. Com isso, ao maximizarmos a margem de separação, chegamos ao modelo com a maior capacidade de classficar
corretamente os registros.

O modelo disponibiliza 2 hiperparâmetros, C e $\gamma$. O primeiro, C, é um parâmetro de regularização da SVM, e define a
margem utilizada pelo modelo para determinar o quanto de erro é aceitável. Isso permite controlar a troca entre a
fronteira de decisão e o termo de classificação errônea. Quando C estiver alto, o modelo classificará um número maior de
pontos, o que também pode ocasionar perda de acurácia e overfitting. Já o hiperparâmetro $\gamma$ define o quanto a
distância entre os pontos influencia o cálculo dos hiperplanos. Quanto maior for Gamma, mais influência possuem pontos
próximos e maior a probabilidade de overfitting. Por outro lado, quanto menor for Gamma, maior a influência de pontos
mais distantes e mais generalista o modelo.

\subsection{Redes Neurais}



\section{Resultados}
\label{resultados}

\subsection{Visualização e Caracterização dos dados}

Conforme apresentado na matriz de variáveis nulas (figura \ref{null_matrix}), algumas colunas como \textit{agent} e
\textit{company} possuem entradas com valores nulos, cuja manutenção afetaria as análises efetuadas. Como a variável que
define a empresa associada à reserva é nula em 94\% das entradas, optou-se por removê-la. Aproveitou-se também para
remover variáveis intuitivamente irrelevantes para o modelo, como nome, e-mail e telefone. Após isso, foi possível
remover todas as entradas contendo valores nulos, já que representavam uma pequena parte do dataset utilizado
($\approx10\%$).

\begin{figure}[h!]
    \centerline{\includegraphics[scale=0.3]{null_matrix.png}}
    \caption{Matriz de variáveis nulas.}
    \label{null_matrix}
\end{figure}

A figura \ref{heatmap} apresenta a matriz de correlação dos atributos, pela qual observa-se a
ausência de fortes correlações, exceto entre as variáveis \textit{arrival\_date\_week\_number} e
\textit{arrival\_date\_year}.

\begin{figure}[h!]
    \centerline{\includegraphics[scale=0.25]{heatmap.png}}
    \caption{Matriz de correlação de atributos.}
    \label{heatmap}
\end{figure}

Como uma etapa de engenharia de atributos, optou-se por tratar algumas informações pouco relevantes para o modelo em sua
forma original. Para isso, um novo atributo de localização (\textit{guest\_location}) foi criado para substituir o
atributo de país, mapeando Portugal em "Local" e outros países em "Internacional", já que o número de reservas
provenientes de Portugal era inicialmente muito maior que as de outros países individualmente. Além disso, as variáveis
\textit{children} e \textit{babies} foram somadas em uma nova variável \textit{kids}. Por final, dois novos atributos
\textit{total\_guests} e \textit{total\_stays} foram criados a fim de representar, respectivamente, as somas de hóspedes
(adultos, crianças e bebês) e diárias (diárias em finais de semana e dias de semana).

Após as modificações citadas acima, realizou-se o procedimento de conversão de variáveis categóricas para variáveis
indicadoras. Por exemplo, a variável \textit{meal} foi dividida em 4 novas variáveis: \textit{meal\_FB}, \textit{meal\_HB},
\textit{meal\_SC} e \textit{meal\_Undefined}, que representam as diferentes possibilidades de refeições a serem
escolhidas pelos clientes.

Logo após a etapa de tratamento das variáveis, como tarefa de pré-processamento e com o objetivo de ajustar as escalas
das diferentes variáveis, padronizou-se o dataset. Para isso, foi utilizada a funcionalidade de \texttt{StandardScaler}
do \textit{scitkit learn} \cite{standard_scaler}. Sendo assim, prosseguiu-se para a spearação dos subconjuntos de
treinamento e testes e posterior treinamento dos modelos, cujos resultados são apresentados nas subseções a seguir.

Antes de apresentar os resultados dos treinamentos propriamente ditos, é importante ressaltar o procedimento de
validação adotado. Essencialmente, foi utilizada a técnica de validação cruzada, que consiste na divisão do conjunto de
treinamento em $n$ subjconjuntos, os quais são utilizados para treinar os modelos $n$ vezes, validando o modelo para
diferentes entradas e gerando estatísticas que permitem avaliar seu comportamento de forma mais aprofundada. Tal técnica
é especialmente relevante para os modelos que disponibilizam hiperparâmetros, pois permite avaliar diferentes conjuntos
de hiperparâmetros e decidir o que propicia o melhor modelo. Para o caso de modelos com hiperparâmetros, utilizou-se a
função de \texttt{GridSearchCV} do \textit{scikit learn} \cite{grid_search_cv}, que possibilita a definição de uma
matriz de hiperparâmetros a serem estudados. Para todas as validações cruzadas foi utilizado o mesmo split e a mesma
semente de randomização.

\begin{itemize}
    \color{red}
        \item Visualização e Caracterização dos dados (distribuições, correlações, etc.)
        \item Descrição do procedimento de validação (validação cruzada)
        \item Resultados dos modelos lineares:
            \begin{enumerate}
                \item Regressão Linear / Regressão Logística
                \item Classificação Bayesiana (problemas de classificação)
            \end{enumerate}
        \item Resultados dos modelos não lineares
            \begin{enumerate}
                \item Árvores de decisão
                \item Random Forest (testar pelo menos 2 opções de hiperparâmetros)
                \item Gradient Boosting (testar pelo menos 2 opções de hiperparâmetros)
                \item SVM (testar pelo menos 2 opções de hiperparâmetros)
                \item Redes Neurais (testar pelo menos 3 topologias/hiperparâmetros)
            \end{enumerate}
        \item Discussão e comparação dos resultados
\end{itemize}

\subsection{Métricas de comparação}

Diversas métricas foram calculadas para comparar os modelos, as quais estão descritas abaixo, onde  $VP$, $VN$, $FP$ e
$FN$ representam, respectivamente, os verdadeiros positivos, verdadeiros negativos, falso positivos e falso negativos.

\begin{itemize}
    \item \textbf{Acurácia}: dentre todas as classificações, quantas o modelo classificou corretamente. É calculada pela
    seguinte equação:
    \begin{equation}
        A = \frac{VP + FN}{VP + VN + FP + FN}
    \end{equation}
    \item \textbf{Precisão}: dentre todas as classificações positivas que o modelo fez, quantas são de fato positivas. É
    calculada pela seguinte equação:
    \begin{equation}
        P = \frac{VP}{VP + FP}
    \end{equation}
    \item \textbf{Revocação}: dentre todos os registros que são de fato positivos, quantos o modelo classificou como
    positivo. Dada pela seguinte equação:
    \begin{equation}
        R = \frac{VP}{VP + FN}
    \end{equation}
    \item \textbf{F1-score}: média harmônica entre precisão e revocação. Dado pela seguinte equação:
    \begin{equation}
        F1 = \frac{2*P*R}{P+R}
    \end{equation}
\end{itemize}

Dentre as estatísticas apresentadas acima, adotou-se o \textit{F1-score} como métrica de comparação entre os diferentes
modelos. Isso, pois ele indica a capacidade do modelo apresentar uma boa sensibilidade sem prejudicar a precisão e
vice-versa. À princípio, havia-se adotado a acurácia como métrica de comparação, mas acabou-se rejeitando-a por conta do
pequeno desbalanceamento apresentado pelo dataset, o que faz com quê a acurácia seja tendenciosa para a classe dominante.

\subsection{Modelos lineares}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
            & \textbf{Regressão Logística} & \textbf{Classificação Bayesiana} \\
        \hline
        \textbf{Precisão} & $0.794 \pm 0.005$ & $0.700 \pm 0.005$ \\
        \hline
        \textbf{F1-score} & $0.788 \pm 0.005$ & $0.484 \pm 0.005$ \\
        \hline
        \textbf{Acurácia} & $0.793 \pm 0.005$ & $0.526 \pm 0.005$ \\
        \hline
        \textbf{Recall} & $0.793 \pm 0.005$ & $0.526 \pm 0.005$ \\
        \hline
    \end{tabular}
    \caption{Resultados para modelos lineares.}
    \label{linear_results}
\end{table}

A tabela \ref{linear_results} apresenta os resultados para os modelos lineares de Regressão Logística e Classificação
Bayesiana. Como observa-se, o segundo teve uma performance muito baixa, com \textit{F1-score} de apenas $0.484$.
Isso é esperado dada a característica da Classificação Bayesiana de considerar apenas as probabilidades condicionais
individuais de cada atributo e a variável alvo, ignorando portanto as correlações entre os atributos. A regressão
logística também apresentou performance elevada, com \textit{F1-score} de $0.788$, indicando que a superfície de decisão
do problema não é bem aproximada por um sistema linear.

Como os modelos lineares estudados não disponibilizam hiperparâmetros, não há mais discussões a serem feitas sobre eles.

\subsection{Modelos não lineares}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
            & \textbf{Árvore de decisão} & \textbf{Random Forest} & \textbf{Gradient Boosting} \\
        \hline
        \textbf{Precisão} & $0.779 \pm 0.009$ & $0.993 \pm 0.005$ & $0.765 \pm 0.005$ \\
        \hline
        \textbf{F1-score} & $0.764 \pm 0.013$ & $0.995 \pm 0.005$ & $0.802 \pm 0.005$ \\
        \hline
        \textbf{Acurácia} & $0.772 \pm 0.008$ & $0.996 \pm 0.005$ & $0.853 \pm 0.005$ \\
        \hline
        \textbf{Recall} & $0.772 \pm 0.008$ & $0.996 \pm 0.005$ & $0.844 \pm 0.005$ \\
        \hline
    \end{tabular}
\end{table}
\begin{table}[h!]
\centering
    \begin{tabular}{|c|c|c|}
        \hline
            & \textbf{SVM} & \textbf{Redes Neurais} \\
        \hline
        \textbf{Precisão} & $0.824 \pm 0.005$ & $0.843 \pm 0.005$ \\
        \hline
        \textbf{F1-score} & $0.850 \pm 0.005$ & $0.790 \pm 0.005$ \\
        \hline
        \textbf{Acurácia} & $0.886 \pm 0.005$ & $0.850 \pm 0.005$ \\
        \hline
        \textbf{Recall} & $0.877 \pm 0.005$ & $0.755 \pm 0.005$ \\
        \hline
    \end{tabular}
    \caption{Resultados para modelos não lineares.}
    \label{non_linear_results}
\end{table}

A tabela \ref{non_linear_results} apresenta os resultados para os modelos não lineares estudados. Observa-se que a
performance demonstrada é consideravelmente superior que as apresentadas pelos modelos lineares, confirmando a
suspeita do final da subseção anterior de que o problema é melhor aproximado por uma superfície de decisão não linear.
O único modelo cujo treinamento não envolveu estudo de hiperparâmetrosdo foi o de Árvore de Decisão. Para os outros, os
resultados e estudo de hiperparâmetros será feito a seguir.

Para o treinamento da Random Forest, variou-se o número de estimadores utilizados para sua construção, que é basicamente
o número de árvores de decisão combinadas. Os dois valores utilizados foram de 10 e 100 estimadores, que apresentaram
respectivamente, \textit{F1-score} médio na validação cruzada de $0.871 \pm 0.003$ e $0.881 \pm 0.002$. Como era
esperado, o aumento do número de estimadores aumenta a performance do modelo, mas prejudica o tempo de treinamento. Com
isso, o modelo utilizado para a comparação foi o com 100 estimadores.

Já para o Gradient Boosting, o estudo dos hiperparâmetros envolveu uma maior variedade, que são apresentados na tabela
\ref{gb_hiperparams}, disponível abaixo.

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Número de estimadores} & \textbf{Taxa de aprendizado} & \textbf{Subamostras} & \textbf{F1-score médio} \\
        \hline
        10 & $0.1$ & $0.5$ & $0.713 \pm 0.008$ \\
        \hline
        10 & $0.1$ & $1.0$ & $0.713 \pm 0.011$ \\
        \hline
        10 & 1 & $0.5$ & $0.828 \pm 0.003$ \\
        \hline
        10 & 1 & $1.0$ & $0.830 \pm 0.003$ \\
        \hline
        100 & $0.1$ & $0.5$ & $0.840 \pm 0.003$ \\
        \hline
        100 & $0.1$ & $1.0$ & $0.839 \pm 0.002$ \\
        \hline
        100 & 1 & $0.5$ & $0.850 \pm 0.004$ \\
        \hline
        100 & 1 & $1.0$ & $0.857 \pm 0.005$ \\
        \hline
    \end{tabular}
    \caption{Validação cruzada de hiperparâmetros para Gradient Boosting.}
    \label{gb_hiperparams}
\end{table}

Observa-se, portanto, que o melhor conjunto de hiperparâmetros é dado por número de estimadores = 100, taxa de
aprendizado = 1 e Subamostras = 1. Isso faz sentido, pois um maior número de estimadores tende a aumentar a acurácia do
modelo, e a taxa de aprendizado funciona como uma penalidade para cada árvore de decisão que compõe o modelo.

Para o modelo de SVM, não foi possível realizar um estudo muito aprofundado dos hiperparâmetros, pois o tempo de
treinamento de cada modelo foi muito elevado para o conjunto de treinamento utilizado, que é consideravelmente grande.
Portanto, variou-se apenas o hiperparâmetro C, para o qual adotou-se o valor de 1 e 100, obtendo-se respectivamente
\textit{F1-score} médio de $0.841 \pm 0.001$ e $0.850 \pm 0.002$. Logo, o aumento de C levou a uma melhor acurácia, o
que pode se justificar pelo fato de que este hiperparâmetro funciona como regularizador, definindo a margem utilizada
pelo modelo para determinar o quanto de erro é aceitável. Logo, quanto maior C, mais pontos são classificados.
Importante se atentar que um aumento indiscriminado de C pode levar a uma eventual perda de acurácia com ocorrência de
overfitting.

Por fim, para o modelo de Redes Neurais foram testadas diferentes topologias, cujas descrições e resultados de
\textit{F1-score} médio são apresentados na tabela \ref{nn_topology}. Para as 3 tropologias adotadas, utilizou-se
otimizador \textit{Adam}, função de custo de Entropia Cruzada Binária e regularizadores do tipo L2 a fim de evitar
overfitting e consequente perda de acurácia.

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Número de estimadores} & \textbf{Taxa de aprendizado} \\
        \hline
        Largura 12, 1 camada escondida & $0.774 \pm 0.003$ \\
        \hline
        Largura 133, 2 camadas escondidas & $0.790 \pm 0.003$ \\
        \hline
        Largura 133, 5 camadas escondidas & $0.784 \pm 0.002$ \\
        \hline
    \end{tabular}
    \caption{Validação cruzada de hiperparâmetros para Rede Neural.}
    \label{nn_topology}
\end{table}

Nesse caso, concluiu-se que a topologia onde foi utilizada largura de 133 e 2 camadas escondidas foi a que apresentou
melhor performance. A conclusão a que chegamos foi de que o aumento do número de camadas internas, bem como da largura
da rede neural foi inicialmente benéfico, mas ao seguir com o aumento ocasiona-se a ocorrência de overfitting e perda
de acurácia devido à construção de caminhos complexos pouco eficientes.

\section{Conclusões}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Modelo} & \textbf{Melhor \textit{F1-score}} \\
        \hline
        Random Forest & $0.995 \pm 0.005$ \\
        \hline
        SVM & $0.850 \pm 0.005$ \\
        \hline
        Gradient Boosting & $0.802 \pm 0.005$ \\
        \hline
        Redes Neurais & $0.790 \pm 0.005$ \\
        \hline
        Regressão Logística & $0.788 \pm 0.005$ \\
        \hline
        Árvore de Decisão & $0.764 \pm 0.013$ \\
        \hline
        Classificação Bayesiana & $0.484 \pm 0.005$ \\
        \hline
    \end{tabular}
    \caption{Resumo de resultados dos diferentes modelos treinados.}
    \label{compiled_results}
\end{table}

A partir da tabela \ref{compiled_results}, conclui-se que o modelo que apresentou a melhor performance (avaliada através
da métrica de \textit{F1-score}) foi o de Random Forest. Além disso, os 4 melhores modelos treinados foram do tipo
não-linear, o que leva à conclusão de que a superfície de decisão do problema em questão é melhor ajustada por um
sistema não-linear.

\begin{itemize}
    \color{red}
        \item Discussão sobre as características do problema
        \item Discussão dos resultados obtidos em função das características do problema
        \item Recomendação sobre o melhor modelo para a aplicação
        \item Trabalhos futuros (opcional)
\end{itemize}

\begin{thebibliography}{1}
    \bibitem{kaggle} \url{https://www.kaggle.com/mojtaba142/hotel-booking}. Acessado em 20/02/2022.
    \bibitem{colab} \url{https://colab.research.google.com/}.
    \bibitem{evsukoff} Evsukoff, A. Ensinando Máquinas, 2017.
    \bibitem{decision_tree} M. Wagner, H. Principles of Operations Research, 1975.
    \bibitem{random_forest} \url{https://en.wikipedia.org/wiki/Random_forest}.
    \bibitem{standard_scaler} \url{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html}.
    \bibitem{grid_search_cv} \url{https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html}.
\end{thebibliography}

\end{document}
